{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X1kiO9kACE6s"
   },
   "source": [
    "## 1a. Import the libraries and sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7QG7sxmoCIvN"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/leticiachoo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/leticiachoo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     /Users/leticiachoo/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "import gensim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "# Downloads the NLTK package\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b. Display sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentences:\n",
      "\n",
      "The Fulton County Grand Jury said Friday an investigation of Atlanta's recent primary election produced `` no evidence '' that any irregularities took place. \n",
      "\n",
      "The jury further said in term-end presentments that the City Executive Committee, which had over-all charge of the election, `` deserves the praise and thanks of the City of Atlanta '' for the manner in which the election was conducted. \n",
      "\n",
      "The September-October term jury had been charged by Fulton Superior Court Judge Durwood Pye to investigate reports of possible `` irregularities '' in the hard-fought primary which was won by Mayor-nominate Ivan Allen Jr.. \n",
      "\n",
      "`` Only a relative handful of such reports was received '', the jury said, `` considering the widespread interest in the election, the number of voters and the size of this city ''. \n",
      "\n",
      "The jury said it did find that many of Georgia's registration and election laws `` are outmoded or inadequate and often ambiguous ''. \n",
      "\n",
      "It recommended that Fulton legislators act `` to have these laws studied and revised to the end of modernizing and improving them ''. \n",
      "\n",
      "The grand jury commented on a number of other topics, among them the Atlanta and Fulton County purchasing departments which it said `` are well operated and follow generally accepted practices which inure to the best interest of both governments ''. \n",
      "\n",
      "Merger proposed \n",
      "\n",
      "However, the jury said it believes `` these two offices should be combined to achieve greater efficiency and reduce the cost of administration ''. \n",
      "\n",
      "The City Purchasing Department, the jury said, `` is lacking in experienced clerical personnel as a result of city personnel policies ''. \n",
      "\n",
      "It urged that the city `` take steps to remedy '' this problem. \n",
      "\n",
      "Implementation of Georgia's automobile title law was also recommended by the outgoing jury. \n",
      "\n",
      "It urged that the next Legislature `` provide enabling funds and re-set the effective date so that an orderly implementation of the law may be effected ''. \n",
      "\n",
      "The grand jury took a swipe at the State Welfare Department's handling of federal funds granted for child welfare services in foster homes. \n",
      "\n",
      "`` This is one of the major items in the Fulton County general assistance program '', the jury said, but the State Welfare Department `` has seen fit to distribute these funds through the welfare departments of all the counties in the state with the exception of Fulton County, which receives none of this money. \n",
      "\n",
      "The jurors said they realize `` a proportionate distribution of these funds might disable this program in our less populous counties ''. \n",
      "\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "print('The sentences:\\n')\n",
    "\n",
    "for i, sent in enumerate(brown.sents()):\n",
    "    text = ''\n",
    "    \n",
    "    for w in sent:\n",
    "        text += (' ' if text and (w not in ('`', '.', ',', '\\'', '\"\"', '(', '[') and text[-1] not in {'(', ']'}) else '') + w\n",
    "    \n",
    "    print(text, '\\n')\n",
    "    \n",
    "    if i == 15:\n",
    "        break\n",
    "        \n",
    "print('...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2a. Generate word embeddings\n",
    "\n",
    "Uses the sample corpus [brown](https://www.nltk.org/book/ch02.html) from Brown University.\n",
    "\n",
    "Credits: [@alvations](https://www.kaggle.com/alvations/word2vec-embedding-using-gensim-and-nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from nltk.corpus import brown\n",
    "\n",
    "model = gensim.models.Word2Vec(brown.sents())\n",
    "model.save('brown.embedding')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2b. Display similarities for a single word\n",
    "\n",
    "For cosine distance,\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/442/1*UODvtQMybHE8c0eL3K5z5A.png\" width=\"300\" height=\"auto\" />\n",
    "\n",
    "(Source: [Prabhu, 2019](https://towardsdatascience.com/understanding-nlp-word-embeddings-text-vectorization-1a23744f7223))\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/697/0*XMW5mf81LSHodnTi.png\" width=\"300\" height=\"auto\" />\n",
    "\n",
    "(Source: [Dhruvil Karani, 2018](https://towardsdatascience.com/understanding-nlp-word-embeddings-text-vectorization-1a23744f7223))\n",
    "\n",
    "Read more on `Word2Vec` for gensim [here](https://radimrehurek.com/gensim/models/word2vec.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word we are checking \"university\"\n",
      "\n",
      "Vector for 100 embeddings:\n",
      "\n",
      " [ 0.11175527  0.25669736  0.20066865  0.11175066 -0.06460495 -0.33296835\n",
      "  0.20352826  0.3468266  -0.30710742 -0.28286117  0.16939154 -0.22782493\n",
      "  0.19033255  0.16709751  0.24337387 -0.16267173  0.26980072 -0.14518285\n",
      " -0.52309054 -0.51736414  0.2850579  -0.11510846  0.48376077  0.07662556\n",
      " -0.05919393 -0.13305968 -0.23038775  0.01760273 -0.21032424  0.23470333\n",
      "  0.21679243 -0.06695802  0.28115085 -0.37063724 -0.17731045  0.05806558\n",
      " -0.1888917  -0.05340989 -0.34433    -0.05935063  0.01267142 -0.2682686\n",
      "  0.17947511  0.1153377   0.20314875 -0.00816581 -0.01876937 -0.02480987\n",
      "  0.09931239  0.31092817  0.01604638 -0.2854515  -0.25131583 -0.18981163\n",
      " -0.10706858 -0.22966878  0.17690061  0.05214861 -0.06181134 -0.07889867\n",
      "  0.02951878  0.2008032  -0.03759096 -0.1692586  -0.18953413  0.4518703\n",
      "  0.02252458  0.284502   -0.2633548   0.36973944  0.2051202   0.1467263\n",
      "  0.21679464 -0.00282996  0.33435     0.08990233  0.10696647  0.04716726\n",
      "  0.02949491 -0.12957829 -0.11856832  0.01189783 -0.21706994  0.07342278\n",
      " -0.18661991 -0.01761125  0.19016565  0.01766774  0.16560157  0.07582062\n",
      "  0.42547068 -0.15200028 -0.12019517  0.11297048  0.3234664   0.1194476\n",
      "  0.16742449 -0.3638934  -0.15223013  0.0518372 ] \n",
      "\n",
      "Picking words with likely similarity to \"university\":\n",
      "\n",
      "         Word  Cos. Score  Cos. Distance                           Vector\n",
      "0     school    0.815275       0.184725   [-0.10185752, .., -0.08298204]\n",
      "1    college    0.923383       0.076617   [0.061086845, .., 0.016961114]\n",
      "2  technical    0.841437       0.158563   [0.07291248, .., -0.057412386]\n",
      "3  education    0.799651       0.200349  [-0.093239695, .., 0.033499084]\n",
      "4     degree    0.891829       0.108171   [-0.050251093, .., 0.03972738]\n",
      "5  knowledge    0.827428       0.172572   [0.052564133, .., -0.06897819]\n",
      "6   research    0.830721       0.169279     [0.06329767, .., 0.29495242] \n",
      "\n",
      "Top 20 similar words to \"university\":\n",
      "\n",
      "             Word  Cos. Score  Cos. Distance                           Vector\n",
      "0     membership    0.954328       0.045672   [0.089208566, .., 0.057455722]\n",
      "1     profession    0.953390       0.046610  [0.035071146, .., -0.039941985]\n",
      "2   neighborhood    0.952823       0.047177   [0.033845503, .., 0.061511133]\n",
      "3   congregation    0.951294       0.048706   [0.11205729, .., -0.048634265]\n",
      "4      selection    0.948130       0.051870    [0.093614645, .., 0.08860301]\n",
      "5      residence    0.945443       0.054557     [0.05476407, .., 0.03005006]\n",
      "6      inception    0.940743       0.059258    [0.031326905, .., -0.0315369]\n",
      "7           seam    0.940643       0.059357   [0.04099605, .., -0.016436735]\n",
      "8    instruction    0.940045       0.059955     [0.0879309, .., -0.03569325]\n",
      "9          score    0.939726       0.060274    [0.111002214, .., 0.08458682]\n",
      "10    restaurant    0.939497       0.060503    [0.14641544, .., -0.06071343]\n",
      "11        dreams    0.939129       0.060871   [0.05684109, .., -0.044060916]\n",
      "12          site    0.938321       0.061679     [0.11732747, .., 0.12525614]\n",
      "13       payment    0.937536       0.062464      [0.30090055, .., 0.0290332]\n",
      "14         stint    0.937413       0.062587  [0.048861172, .., 0.0068973773]\n",
      "15         lands    0.936704       0.063296  [-0.012616426, .., 0.016406773]\n",
      "16  independence    0.936458       0.063542   [0.13958427, .., -0.090918414]\n",
      "17        Empire    0.936359       0.063641   [0.029067492, .., 0.058421735]\n",
      "18     catalogue    0.935572       0.064428   [0.021995043, .., 0.030202596]\n",
      "19        leader    0.935530       0.064470    [0.16236071, .., -0.02782517] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec.load('brown.embedding')\n",
    "\n",
    "word = 'university'\n",
    "cherry_pick = ('school', 'college', 'technical', 'education', 'degree', 'knowledge', 'research')\n",
    "trunc_vector = lambda w: [model.wv[w][0], '..', model.wv[w][-1]]\n",
    "\n",
    "print(f'Word we are checking \"{word}\"\\n')\n",
    "print(f'Vector for {len(model.wv[word])} embeddings:\\n\\n', model.wv[word], '\\n')\n",
    "\n",
    "print(f'Picking words with likely similarity to \"{word}\":\\n\\n',\n",
    "    pd.DataFrame(list(map(lambda w: (\n",
    "        w, \n",
    "        model.wv.similarity(word, w), \n",
    "        model.wv.distances(word, [w])[0],\n",
    "        trunc_vector(w)\n",
    "    ), cherry_pick)),\n",
    "    columns=['Word', 'Cos. Score', 'Cos. Distance', 'Vector'])\n",
    ", '\\n')\n",
    "\n",
    "print(f'Top 20 similar words to \"{word}\":\\n\\n',\n",
    "    pd.DataFrame([(\n",
    "        wv[0], \n",
    "        wv[1],\n",
    "        model.wv.distances(word, [wv[0]])[0],\n",
    "        trunc_vector(wv[0])\n",
    "    ) for wv in model.wv.most_similar(positive=[word], topn=20)],\n",
    "    columns=['Word', 'Cos. Score', 'Cos. Distance', 'Vector'])\n",
    ", '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMx/KsxUDrn2M5QbIb03B9p",
   "collapsed_sections": [],
   "name": "natural_language_processing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
