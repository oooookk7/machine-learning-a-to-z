{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import libraries and sample dataset\n",
    "\n",
    "- Episode starts with taxi at a random square and passenger at random location, and ends with the passenger being dropped off at a specified destination.\n",
    "- 4 destinations: R(ed), G(reen), Y(ellow), and B(lue)\n",
    "\n",
    "There are `500` discrete states as `25` (taxi positions) × `5` (possible passenger locations) × `4` (destination).\n",
    "\n",
    "| Location index | Description |\n",
    "| -- | --- |\n",
    "| `0` | R(ed) |\n",
    "| `1` | G(reen) |\n",
    "| `2` | Y(ellow) |\n",
    "| `3` | B(lue) |\n",
    "| `4` | In taxi |\n",
    "\n",
    "There are `6` discrete deterministic actions:\n",
    "\n",
    "| Action index | Description |\n",
    "| -- | -- |\n",
    "| `0` | move south |\n",
    "| `1` | move north |\n",
    "| `2` | move east |\n",
    "| `3` | move west |\n",
    "| `4` | pickup passenger |\n",
    "| `5` | drop off passenger |\n",
    "\n",
    "The reward functions acts like this:\n",
    "\n",
    "| Reward value | Description |\n",
    "| -- | -- |\n",
    "| `-1` | Per step reward |\n",
    "| `+20` | Delivering passenger |\n",
    "| `-10` | Executing \"pickup\" or \"drop-off\" actions illegally |\n",
    "\n",
    "### Rendering\n",
    "\n",
    "These are the color indications,\n",
    "\n",
    "| Color | Description |\n",
    "| -- | -- |\n",
    "| Blue | Passenger |\n",
    "| Magenta | Destination |\n",
    "| Yellow | Empty taxi |\n",
    "| Green | Full taxi |\n",
    "\n",
    "These are the letter indications,\n",
    "\n",
    "| Letter | Description |\n",
    "| -- | -- |\n",
    "| R | R(ed) destination |\n",
    "| G | G(reen) destination |\n",
    "| Y | Y(ellow) destination |\n",
    "| B | B(lue) destination |\n",
    "\n",
    "The block represent the taxi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[34;1mB\u001b[0m:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "streets = gym.make(\"Taxi-v3\").env\n",
    "streets.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Find optimized `π(s|a)` and `v(s)` from Policy Iteration\n",
    "\n",
    "Credits to [angps95@kaggle](https://www.kaggle.com/angps95/intro-to-reinforcement-learning-with-openai-gym/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed with 12 iterations\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Where Δ is delta of change, and Θ is acceptable threshold,\n",
    "\n",
    "1. Set Θ\n",
    "2. Start with π(s|a) = [[1, .., 1], .., [1, ..]]\n",
    "3. Find V(s),\n",
    "    a. Set Δ = 0\n",
    "    b. For each s ∈ S,\n",
    "        1. Find max{V(s)}\n",
    "        2. Set Δ = max(Δ, |V_max - V[s]|)\n",
    "        3. V[s] = V_max\n",
    "    c. If Θ < Δ, repeat b\n",
    "4. Check if convergent,\n",
    "    a. For s ∈ S,\n",
    "        1. Find max{Q(s, a ∈ A)}\n",
    "        2. If Q_max != V[s], not CONVERGENT\n",
    "    b. If not CONVERGENT, repeat a \n",
    "5. Return π(s|a) and v(s)\n",
    "\n",
    "Useful equations,\n",
    "Q*(s, a) = ρ(s,s')^a * [R(s, a, s') + γ * V*(s')]\n",
    "V*(s) = π(s|a) * (Q*(s, a))\n",
    "\"\"\"\n",
    "discount_factor = 0.95\n",
    "theta = 0.00001\n",
    "\n",
    "no_of_states = streets.observation_space.n\n",
    "no_of_actions = streets.action_space.n\n",
    "no_of_iter = 0\n",
    "\n",
    "policy = np.ones([no_of_states, no_of_actions]) / no_of_actions\n",
    "V = np.zeros(no_of_states)\n",
    "\n",
    "\n",
    "def opt_Ve():\n",
    "    Ve = np.zeros(no_of_states)\n",
    "\n",
    "    while True:\n",
    "        delta = 0\n",
    "\n",
    "        for state in range(no_of_states):\n",
    "            Ve_state_value = 0\n",
    "\n",
    "            for action, action_prob in enumerate(policy[state]):\n",
    "                for trans_prob, next_state, reward, _ in streets.P[state][action]:\n",
    "                    Qe_state_value = trans_prob * (reward + discount_factor * Ve[next_state])\n",
    "                    Ve_state_value += action_prob * Qe_state_value\n",
    "\n",
    "            delta = max(delta, np.abs(Ve_state_value - Ve[state]))\n",
    "            Ve[state] = Ve_state_value\n",
    "\n",
    "        if delta < theta:\n",
    "            break\n",
    "\n",
    "    return np.array(Ve)\n",
    "\n",
    "\n",
    "def opt_Q(state):\n",
    "    Q = np.zeros(no_of_actions)\n",
    "\n",
    "    for action in range(no_of_actions):\n",
    "        for trans_prob, next_state, reward, _ in streets.P[state][action]:\n",
    "            Q[action] += trans_prob * (reward + discount_factor * V[next_state])\n",
    "\n",
    "    return Q\n",
    "\n",
    "\n",
    "while True:\n",
    "    V = opt_Ve()\n",
    "    converged = True\n",
    "    \n",
    "    for state in range(no_of_states):\n",
    "        action_e = np.argmax(policy[state])\n",
    "        action_max = np.argmax(opt_Q(state))\n",
    "\n",
    "        if action_e != action_max:\n",
    "            converged = False\n",
    "        \n",
    "        policy[state] = np.eye(no_of_actions)[action_max]\n",
    "    \n",
    "    no_of_iter += 1\n",
    "\n",
    "    if converged:\n",
    "        break\n",
    "\n",
    "print(f'Completed with {no_of_iter} iterations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Find the amount of steps taken upon using model algorithm\n",
    "\n",
    "Reset the environment after having pre-learnt it and find the amount of steps taken to reach goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def episode_steps():\n",
    "    current_state = streets.reset()\n",
    "    reward = 0\n",
    "    no_of_steps = 0\n",
    "\n",
    "    while reward != 20:\n",
    "        state, reward, _, _ = streets.step(np.argmax(policy[current_state]))  \n",
    "        current_state = state\n",
    "        no_of_steps += 1\n",
    "    \n",
    "    return no_of_steps\n",
    "\n",
    "episode_dist = np.array([episode_steps() for i in range(10000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Display episode steps distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "bins = [i + 1 for i in range(np.min(episode_dist), np.max(episode_dist))]\n",
    "\n",
    "ax.hist(episode_dist, bins=bins)\n",
    "ax.set_title(\"Episode Steps Distribution\")\n",
    "ax.set_xticks(bins)\n",
    "ax.set_xlabel('Steps')\n",
    "ax.set_ylabel('No. of episodes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
