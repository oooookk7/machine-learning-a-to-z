{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import libraries and sample dataset\n",
    "\n",
    "- Episode starts with taxi at a random square and passenger at random location, and ends with the passenger being dropped off at a specified destination.\n",
    "- 4 destinations: R(ed), G(reen), Y(ellow), and B(lue)\n",
    "\n",
    "There are `500` discrete states as `25` (taxi positions) × `5` (possible passenger locations) × `4` (destination).\n",
    "\n",
    "| Location index | Description |\n",
    "| -- | --- |\n",
    "| `0` | R(ed) |\n",
    "| `1` | G(reen) |\n",
    "| `2` | Y(ellow) |\n",
    "| `3` | B(lue) |\n",
    "| `4` | In taxi |\n",
    "\n",
    "There are `6` discrete deterministic actions:\n",
    "\n",
    "| Action index | Description |\n",
    "| -- | -- |\n",
    "| `0` | move south |\n",
    "| `1` | move north |\n",
    "| `2` | move east |\n",
    "| `3` | move west |\n",
    "| `4` | pickup passenger |\n",
    "| `5` | drop off passenger |\n",
    "\n",
    "The reward functions acts like this:\n",
    "\n",
    "| Reward value | Description |\n",
    "| -- | -- |\n",
    "| `-1` | Per step reward |\n",
    "| `+20` | Delivering passenger |\n",
    "| `-10` | Executing \"pickup\" or \"drop-off\" actions illegally |\n",
    "\n",
    "### Rendering\n",
    "\n",
    "These are the color indications,\n",
    "\n",
    "| Color | Description |\n",
    "| -- | -- |\n",
    "| Blue | Passenger |\n",
    "| Magenta | Destination |\n",
    "| Yellow | Empty taxi |\n",
    "| Green | Full taxi |\n",
    "\n",
    "These are the letter indications,\n",
    "\n",
    "| Letter | Description |\n",
    "| -- | -- |\n",
    "| R | R(ed) destination |\n",
    "| G | G(reen) destination |\n",
    "| Y | Y(ellow) destination |\n",
    "| B | B(lue) destination |\n",
    "\n",
    "The block represent the taxi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "|\u001b[43m \u001b[0m: : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[34;1mB\u001b[0m: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "streets = gym.make(\"Taxi-v3\").env\n",
    "streets.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Find optimized `π(s|a)` and `v(s)` from Policy Iteration\n",
    "\n",
    "Credits to [angps95@kaggle](https://www.kaggle.com/angps95/intro-to-reinforcement-learning-with-openai-gym/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed with 12 iterations\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Where Δ is delta of change, and Θ is acceptable threshold,\n",
    "\n",
    "1. Set Θ, γ\n",
    "2. Start with π(s|a) = [[1, .., 1], .., [1, ..]]\n",
    "3. Find V(s),\n",
    "    a. Set Δ = 0\n",
    "    b. For each s ∈ S,\n",
    "        1. Find max{V(s)}\n",
    "        2. Set Δ = max(Δ, |V_max - V[s]|)\n",
    "        3. V[s] = V_max\n",
    "    c. If Θ < Δ, repeat b\n",
    "4. Check if convergent,\n",
    "    a. For s ∈ S,\n",
    "        1. Find max{Q(s, a ∈ A)}\n",
    "        2. If Q_max != V[s], not CONVERGENT\n",
    "    b. If not CONVERGENT, repeat a \n",
    "5. Return π(s|a) and V(s)\n",
    "\n",
    "Useful equations,\n",
    "Q*(s, a) = ρ(s,s')^a * [R(s, a, s') + γ * V*(s')]\n",
    "V*(s) = π(s|a) * (Q*(s, a))\n",
    "\"\"\"\n",
    "discount_factor = 0.95\n",
    "theta = 0.00001\n",
    "\n",
    "no_of_states = streets.observation_space.n\n",
    "no_of_actions = streets.action_space.n\n",
    "no_of_iter = 0\n",
    "\n",
    "policy = np.ones([no_of_states, no_of_actions]) / no_of_actions\n",
    "V = np.zeros(no_of_states)\n",
    "\n",
    "\n",
    "def opt_Ve():\n",
    "    Ve = np.zeros(no_of_states)\n",
    "\n",
    "    while True:\n",
    "        delta = 0\n",
    "\n",
    "        for state in range(no_of_states):\n",
    "            Ve_state_value = 0\n",
    "\n",
    "            for action, action_prob in enumerate(policy[state]):\n",
    "                for trans_prob, next_state, reward, _ in streets.P[state][action]:\n",
    "                    Qe_state_value = trans_prob * (reward + discount_factor * Ve[next_state])\n",
    "                    Ve_state_value += action_prob * Qe_state_value\n",
    "\n",
    "            delta = max(delta, np.abs(Ve_state_value - Ve[state]))\n",
    "            Ve[state] = Ve_state_value\n",
    "\n",
    "        if delta < theta:\n",
    "            break\n",
    "\n",
    "    return np.array(Ve)\n",
    "\n",
    "\n",
    "def opt_Q(state):\n",
    "    Q = np.zeros(no_of_actions)\n",
    "\n",
    "    for action in range(no_of_actions):\n",
    "        for trans_prob, next_state, reward, _ in streets.P[state][action]:\n",
    "            Q[action] += trans_prob * (reward + discount_factor * V[next_state])\n",
    "\n",
    "    return Q\n",
    "\n",
    "\n",
    "while True:\n",
    "    V = opt_Ve()\n",
    "    converged = True\n",
    "    \n",
    "    for state in range(no_of_states):\n",
    "        action_e = np.argmax(policy[state])\n",
    "        action_max = np.argmax(opt_Q(state))\n",
    "\n",
    "        if action_e != action_max:\n",
    "            converged = False\n",
    "        \n",
    "        policy[state] = np.eye(no_of_actions)[action_max]\n",
    "    \n",
    "    no_of_iter += 1\n",
    "\n",
    "    if converged:\n",
    "        break\n",
    "\n",
    "print(f'Completed with {no_of_iter} iterations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Find the amount of steps taken upon using model algorithm\n",
    "\n",
    "Reset the environment after having pre-learnt it and find the amount of steps taken to reach goal.\n",
    "\n",
    "Display the min, max and avg steps after it is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min steps=6, Avg steps=13.1, Max steps=18\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[35m\u001b[34;1m\u001b[43mY\u001b[0m\u001b[0m\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (Dropoff)\n"
     ]
    }
   ],
   "source": [
    "def episode_steps():\n",
    "    current_state = streets.reset()\n",
    "    reward = 0\n",
    "    no_of_steps = 0\n",
    "\n",
    "    while reward != 20:\n",
    "        state, reward, _, _ = streets.step(np.argmax(policy[current_state]))  \n",
    "        current_state = state\n",
    "        no_of_steps += 1\n",
    "    \n",
    "    return no_of_steps\n",
    "\n",
    "episode_dist = np.array([episode_steps() for i in range(10000)])\n",
    "\n",
    "print(f'Min steps={np.min(episode_dist)}, Avg steps={np.round(np.average(episode_dist), 1)}, Max steps={np.max(episode_dist)}')\n",
    "streets.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Display episode steps distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "bins = [i + 1 for i in range(np.min(episode_dist), np.max(episode_dist))]\n",
    "\n",
    "ax.hist(episode_dist, bins=bins)\n",
    "ax.set_title(\"Episode Steps Distribution\")\n",
    "ax.set_xticks(bins)\n",
    "ax.set_xlabel('Steps')\n",
    "ax.set_ylabel('No. of episodes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
