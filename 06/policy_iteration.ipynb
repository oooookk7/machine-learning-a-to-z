{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import libraries and sample dataset\n",
    "\n",
    "- Episode starts with taxi at a random square and passenger at random location, and ends with the passenger being dropped off at a specified destination.\n",
    "- 4 destinations: R(ed), G(reen), Y(ellow), and B(lue)\n",
    "\n",
    "There are `500` discrete states as `25` (taxi positions) × `5` (possible passenger locations) × `4` (destination).\n",
    "\n",
    "| Location index | Description |\n",
    "| -- | --- |\n",
    "| `0` | R(ed) |\n",
    "| `1` | G(reen) |\n",
    "| `2` | Y(ellow) |\n",
    "| `3` | B(lue) |\n",
    "| `4` | In taxi |\n",
    "\n",
    "There are `6` discrete deterministic actions:\n",
    "\n",
    "| Action index | Description |\n",
    "| -- | -- |\n",
    "| `0` | move south |\n",
    "| `1` | move north |\n",
    "| `2` | move east |\n",
    "| `3` | move west |\n",
    "| `4` | pickup passenger |\n",
    "| `5` | drop off passenger |\n",
    "\n",
    "The reward functions acts like this:\n",
    "\n",
    "| Reward value | Description |\n",
    "| -- | -- |\n",
    "| `-1` | Per step reward |\n",
    "| `+20` | Delivering passenger |\n",
    "| `-10` | Executing \"pickup\" or \"drop-off\" actions illegally |\n",
    "\n",
    "### Rendering\n",
    "\n",
    "These are the color indications,\n",
    "\n",
    "| Color | Description |\n",
    "| -- | -- |\n",
    "| Blue | Passenger |\n",
    "| Magenta | Destination |\n",
    "| Yellow | Empty taxi |\n",
    "| Green | Full taxi |\n",
    "\n",
    "These are the letter indications,\n",
    "\n",
    "| Letter | Description |\n",
    "| -- | -- |\n",
    "| R | R(ed) destination |\n",
    "| G | G(reen) destination |\n",
    "| Y | Y(ellow) destination |\n",
    "| B | B(lue) destination |\n",
    "\n",
    "The block represent the taxi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :\u001b[34;1mG\u001b[0m|\n",
      "| : | : : |\n",
      "|\u001b[43m \u001b[0m: : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "streets = gym.make(\"Taxi-v3\").env\n",
    "streets.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Find optimized `π(s|a)` and `v(s)` from Policy Iteration\n",
    "\n",
    "Credits to [angps95@kaggle](https://www.kaggle.com/angps95/intro-to-reinforcement-learning-with-openai-gym/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed with 12 iterations\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Where Δ is delta of change, and Θ is acceptable threshold,\n",
    "\n",
    "1. Set Θ\n",
    "2. Start with π(s|a) = [[1, .., 1], .., [1, ..]]\n",
    "3. Find V(s),\n",
    "    a. Set Δ = 0\n",
    "    b. For each s ∈ S,\n",
    "        1. Find max{V(s)}\n",
    "        2. Set Δ = max(Δ, |V_max - V[s]|)\n",
    "        3. V[s] = V_max\n",
    "    c. If Θ < Δ, repeat b\n",
    "4. Check if convergent,\n",
    "    a. For s ∈ S,\n",
    "        1. Find max{Q(s, a ∈ A)}\n",
    "        2. If Q_max != V[s], not CONVERGENT\n",
    "    b. If not CONVERGENT, repeat a \n",
    "5. Return π(s|a) and v(s)\n",
    "\n",
    "Useful equations,\n",
    "Q*(s, a) = ρ(s,s')^a * [R(s, a, s') + γ * V*(s')]\n",
    "V*(s) = π(s|a) * (Q*(s, a))\n",
    "\"\"\"\n",
    "discount_factor = 0.95\n",
    "theta = 0.00001\n",
    "\n",
    "no_of_states = streets.observation_space.n\n",
    "no_of_actions = streets.action_space.n\n",
    "no_of_iter = 0\n",
    "\n",
    "policy = np.ones([no_of_states, no_of_actions]) / no_of_actions\n",
    "V = np.zeros(no_of_states)\n",
    "\n",
    "\n",
    "def opt_Ve():\n",
    "    Ve = np.zeros(no_of_states)\n",
    "\n",
    "    while True:\n",
    "        delta = 0\n",
    "\n",
    "        for state in range(no_of_states):\n",
    "            Ve_state_value = 0\n",
    "\n",
    "            for action, action_prob in enumerate(policy[state]):\n",
    "                for trans_prob, next_state, reward, _ in streets.P[state][action]:\n",
    "                    Qe_state_value = trans_prob * (reward + discount_factor * Ve[next_state])\n",
    "                    Ve_state_value += action_prob * Qe_state_value\n",
    "\n",
    "            delta = max(delta, np.abs(Ve_state_value - Ve[state]))\n",
    "            Ve[state] = Ve_state_value\n",
    "\n",
    "        if delta < theta:\n",
    "            break\n",
    "\n",
    "    return np.array(Ve)\n",
    "\n",
    "\n",
    "def opt_Q(state):\n",
    "    Q = np.zeros(no_of_actions)\n",
    "\n",
    "    for action in range(no_of_actions):\n",
    "        for trans_prob, next_state, reward, _ in streets.P[state][action]:\n",
    "            Q[action] += trans_prob * (reward + discount_factor * V[next_state])\n",
    "\n",
    "    return Q\n",
    "\n",
    "\n",
    "while True:\n",
    "    V = opt_Ve()\n",
    "    converged = True\n",
    "    \n",
    "    for state in range(no_of_states):\n",
    "        action_e = np.argmax(policy[state])\n",
    "        action_max = np.argmax(opt_Q(state))\n",
    "\n",
    "        if action_e != action_max:\n",
    "            converged = False\n",
    "        \n",
    "        policy[state] = np.eye(no_of_actions)[action_max]\n",
    "    \n",
    "    no_of_iter += 1\n",
    "\n",
    "    if converged:\n",
    "        break\n",
    "\n",
    "print(f'Completed with {no_of_iter} iterations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Find the amount of steps taken upon using model algorithm\n",
    "\n",
    "Reset the environment after having pre-learnt it and find the amount of steps taken to reach goal.\n",
    "\n",
    "Display the min, max and avg steps after it is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min steps=6, Avg steps=13.1, Max steps=18\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[35m\u001b[34;1m\u001b[43mY\u001b[0m\u001b[0m\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (Dropoff)\n"
     ]
    }
   ],
   "source": [
    "def episode_steps():\n",
    "    current_state = streets.reset()\n",
    "    reward = 0\n",
    "    no_of_steps = 0\n",
    "\n",
    "    while reward != 20:\n",
    "        state, reward, _, _ = streets.step(np.argmax(policy[current_state]))  \n",
    "        current_state = state\n",
    "        no_of_steps += 1\n",
    "    \n",
    "    return no_of_steps\n",
    "\n",
    "episode_dist = np.array([episode_steps() for i in range(10000)])\n",
    "\n",
    "print(f'Min steps={np.min(episode_dist)}, Avg steps={np.round(np.average(episode_dist), 1)}, Max steps={np.max(episode_dist)}')\n",
    "streets.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Display episode steps distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "bins = [i + 1 for i in range(np.min(episode_dist), np.max(episode_dist))]\n",
    "\n",
    "ax.hist(episode_dist, bins=bins)\n",
    "ax.set_title(\"Episode Steps Distribution\")\n",
    "ax.set_xticks(bins)\n",
    "ax.set_xlabel('Steps')\n",
    "ax.set_ylabel('No. of episodes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
