{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import libraries, test data and split into training/test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = pd.read_csv('Social_Network_Ads.csv')\n",
    "x = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Apply Feature scaling\n",
    "This is minimize the feature value so that it'll not only be easier to work with and the data prediction comes out more accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training the K-NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4a. Tabulate decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_inverse = sc.inverse_transform(x_train)\n",
    "x_test_inverse = sc.inverse_transform(x_test)\n",
    "y_prediction = model.predict(x_test)\n",
    "\n",
    "# Imagine calculus riemann sum delta\n",
    "x1_delta = 1\n",
    "x2_delta = 1\n",
    "\n",
    "x1_margin = 10\n",
    "x2_margin = 1000\n",
    "\n",
    "x1, x2 = np.meshgrid(\n",
    "    np.arange(start=x_train_inverse[:, 0].min() - x1_margin, stop=x_train_inverse[:, 0].max() + x1_margin, step=x1_delta),\n",
    "    np.arange(start=x_train_inverse[:, 1].min() - x2_margin, stop=x_train_inverse[:, 1].max() + x2_margin, step=x2_delta)\n",
    ")\n",
    "\n",
    "z = model.predict(sc.transform(np.array([x1.ravel(), x2.ravel()]).T)).reshape(x1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4b. Display graph and details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_classes(x_data_inverse, y_data):\n",
    "    cls_0 = {'x': [], 'y': []}\n",
    "    cls_1 = {'x': [], 'y': []}\n",
    "\n",
    "    for i, ix in enumerate(x_data_inverse):\n",
    "        if y_data[i] == 1:\n",
    "            cls_1['x'].append(ix[0])\n",
    "            cls_1['y'].append(ix[1])\n",
    "        else:\n",
    "            cls_0['x'].append(ix[0])\n",
    "            cls_0['y'].append(ix[1])\n",
    "            \n",
    "    return cls_0, cls_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dots represents the entire data set and their actual predicted class. Green represents class 1 and red represents class 0. The shaded areas of green and red are predicted areas that determines the data point classes. For test data, they are either circled with yellow (predicted 0) and cyan (predicted 1).\n",
    "\n",
    "There is also the confusion matrix to get a sense of the accuracy for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "x_0, x_1 = split_into_classes(x, y)\n",
    "x_test_0, x_test_1 = split_into_classes(x_test_inverse, y_prediction)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_prediction)\n",
    "\n",
    "print(f'Distance algorithm: {model.get_params()[\"metric\"]} (p={model.get_params()[\"p\"]})')\n",
    "print(f'k parameter: {model.get_params()[\"n_neighbors\"]}\\n')\n",
    "\n",
    "print(pd.DataFrame(cm, columns=['Pred. Class 0', 'Pred. Class 1'], index=['Actual Class 0', 'Actual Class 1']), '\\n')\n",
    "print(f'Accuracy score: {accuracy_score(y_test, y_prediction) * 100}%')\n",
    "\n",
    "plt.scatter(x_0['x'], x_0['y'], color='red', label='Class 0')\n",
    "plt.scatter(x_1['x'], x_1['y'], color='green', label='Class 1')\n",
    "\n",
    "plt.scatter(x_test_0['x'], x_test_0['y'], facecolors='none', edgecolors='yellow', label='Pred. Class 0')\n",
    "plt.scatter(x_test_1['x'], x_test_1['y'], facecolors='none', edgecolors='cyan', label='Pred. Class 1')\n",
    "\n",
    "plt.contourf(x1, x2, z, alpha = 0.15, cmap=ListedColormap(('red', 'green')))\n",
    "\n",
    "plt.title('KNN')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Estimated Salary')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
